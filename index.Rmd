---
title: "Practical Machine Learning"
author: "Andrea Bruna"
date: "January 18th, 2017"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

The following project aims to predict how a population of individual performed weight lifting exercises (correctly or incorrectly) according to training data collected from retail wearable fitness trackers.

The training and data sets are available from the following sites:
[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)
[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

More information are provided at the following link: [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har)

From the page linked above: "_Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E)._"

Essentially, all but class "A" records, are related to different mistakes in the execution form of the exercise.

## Initialization and Data Cleaning 

First of all, the required libraries are loaded, the train and test data are downloaded directly from internet and stored as data frame. The random seed set to today's date.

```{r initialize library, load data, set.seed}
library(caret)
library(gbm)
library(randomForest)

train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
set.seed(18012017)
```

A brief data analysis showed that the first seven columns contain factors which are not useful for predictions so they were removed. Furthermore I decided to exclude columns where there are even a single NA value in either the train or test data sets and values from the training sets with a variance near to zero (they would not improve the model).

```{r exploratory data analysis and data cleaning}
names(train)[1:7]

train2 <- train[, colSums(is.na(train)) == 0 | colSums(is.na(test)) == 0 ] 
train2 <- train2[, -c(1:7)]

nzvar <- (nearZeroVar(train2, saveMetrics = TRUE))
train2 <- train2[, (nzvar$nzv==FALSE)]


test2 <- test[, colSums(is.na(train)) == 0 | colSums(is.na(test)) == 0]
test2 <- test2[, -c(1:7)]
test2 <- test2[ , (nzvar$nzv == FALSE)]

```

## Splitting training data

The "clean" training set is split: 60% of the rows will be used to train the model, the remaining 40% to validate and estimate the error rate of the prediction model before applying it to the test data. 

```{r split}
partition <- createDataPartition(train2$classe, p = 0.60, list = FALSE)
training <- train2[partition, ]
cv <- train2[-partition, ]
```

## Training Model(s)

Afterwards two prediction models are generated based on the "cleaned"" training data frame using respectively Stochastic Gradient Boosting and Random Forest.

```{r model training }
modfitgbm <- train(classe ~ ., data = training, method="gbm", 
                   trControl = trainControl(method="repeatedcv", repeats=3, number=4), 
                   verbose=FALSE)

modfitrf <- train(classe ~ ., data = training, method="rf",
                  trControl=trainControl(method="repeatedcv", repeats=3, number=4))
```

## Extimation of o.o.s. error rate

Let's quantify the accuracy of the prediction using the cv set respectively for GBM and RF: 
```{r confusionmatrix}
confusionMatrix(predict(modfitgbm, cv), cv$classe)
confusionMatrix(predict(modfitrf, cv), cv$classe)
```

The accuracy of the two models is quite close however Random Forest provides even more accurate predictions. The accuracy rate is close to 99.12% therefore I expect the out of sample error rate to be around 0.9% and the predictions to be fairly accurate even using the test data.

## Predicted values

Applying the Random Forest model to the test data, we obtain the following predicted values for "classe":
```{r training and crossvalidation }
predict(modfitrf, test2)
table(predict(modfitrf, test2))
```
